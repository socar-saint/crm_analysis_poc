"""ê°„ë‹¨í•œ LLM ê¸°ë°˜ ìš©ì–´ ê²€ì¦ ë„êµ¬"""

import re
import json
import pandas as pd
from typing import Dict, Any, List
from core.llm.domain_knowledge import DomainKnowledge
import litellm
from config.settings import settings

# Azure OpenAI ëª¨ë¸ ì„¤ì •
azure_llm = litellm

def validate_csv_terms_with_llm(csv_file_path: str) -> Dict[str, Any]:
    """CSV íŒŒì¼ì˜ ìš©ì–´ë“¤ì„ LLMìœ¼ë¡œ ê²€ì¦"""
    print("--- Tool: validate_csv_terms_with_llm called ---")
    
    try:
        # 1. CSVì—ì„œ ìš©ì–´ ì¶”ì¶œ
        df = pd.read_csv(csv_file_path)
        all_text = ""
        for col in df.columns:
            if df[col].dtype == 'object':
                all_text += " " + df[col].astype(str).str.cat(sep=" ")
        
        # í•œê¸€ ìš©ì–´ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        korean_terms = re.findall(r'[ê°€-í£]{2,}', all_text)
        english_terms = re.findall(r'[A-Z][a-zA-Z]*', all_text)
        all_terms = list(set(korean_terms + english_terms))
        
        # 2. ë„ë©”ì¸ ìš©ì–´ì‚¬ì „ ë¡œë“œ
        from core.llm.domain_knowledge import DomainTerminology
        domain_terms = DomainTerminology.get_domain_terms()
        technical_terms = DomainTerminology.get_technical_terms()
        business_metrics = DomainTerminology.get_business_metrics()
        all_domain_terms = {**domain_terms, **technical_terms, **business_metrics}
        
        # 3. ë°°ì¹˜ë¡œ ìš©ì–´ ì´í•´ë„ í‰ê°€ (API í˜¸ì¶œ ìµœì í™”)
        term_evaluations = []
        total_score = 0
        
        # ìš©ì–´ ë¹ˆë„ ê³„ì‚°í•˜ì—¬ 10ë²ˆ ì´ìƒ ì‚¬ìš©ëœ ìš©ì–´ë§Œ ë¶„ì„
        from collections import Counter
        korean_counter = Counter(korean_terms)
        english_counter = Counter(english_terms)
        
        # 10ë²ˆ ì´ìƒ ì‚¬ìš©ëœ ìš©ì–´ í•„í„°ë§
        korean_frequent = [term for term, count in korean_counter.items() if count >= 10]
        english_frequent = [term for term, count in english_counter.items() if count >= 10]
        frequent_terms = korean_frequent + english_frequent
        
        # ìƒìœ„ 40ê°œ ìš©ì–´ë¥¼ í•œ ë²ˆì— ë¶„ì„ (10ë²ˆ ì´ìƒ ì‚¬ìš©ëœ ìš©ì–´ ì¤‘ì—ì„œ)
        terms_to_analyze = frequent_terms[:40] if len(frequent_terms) >= 40 else frequent_terms
        print(f"ğŸš€ ë°°ì¹˜ ìš©ì–´ ë¶„ì„ ì¤‘: {len(terms_to_analyze)}ê°œ ìš©ì–´ (10íšŒ ì´ìƒ ì‚¬ìš©ëœ ìš©ì–´ ì¤‘ ìƒìœ„ {len(terms_to_analyze)}ê°œ, API í˜¸ì¶œ 1íšŒ)")
        print(f"ğŸ“Š 10íšŒ ì´ìƒ ì‚¬ìš©ëœ ìš©ì–´ ì´ ê°œìˆ˜: {len(frequent_terms)}ê°œ (í•œê¸€: {len(korean_frequent)}ê°œ, ì˜ë¬¸: {len(english_frequent)}ê°œ)")
        
        # ìš©ì–´ë³„ ì»¨í…ìŠ¤íŠ¸ì™€ ìš©ì–´ì‚¬ì „ ì •ì˜ ìˆ˜ì§‘
        term_data = []
        for term in terms_to_analyze:
            context = ""
            for col in df.columns:
                if df[col].dtype == 'object':
                    mask = df[col].astype(str).str.contains(term, na=False)
                    if mask.any():
                        context = df[mask][col].astype(str).iloc[0][:100]
                        break
            
            dictionary_definition = all_domain_terms.get(term, None)
            term_data.append({
                "term": term,
                "context": context,
                "dictionary_definition": dictionary_definition
            })
        
        # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
        batch_prompt = f"""
        ë‹¤ìŒ ì˜ì¹´ CRM ë§ˆì¼€íŒ… ë°ì´í„°ì˜ ìš©ì–´ë“¤ì„ í•œ ë²ˆì— ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ë¶„ì„í•  ìš©ì–´ë“¤:
        {json.dumps(term_data, ensure_ascii=False, indent=2)}
        
        ë„ë©”ì¸ ìš©ì–´ì‚¬ì „:
        {json.dumps(all_domain_terms, ensure_ascii=False, indent=2)}
        
        ê° ìš©ì–´ì— ëŒ€í•´ ë‹¤ìŒì„ í‰ê°€í•´ì£¼ì„¸ìš”:
        1. ìš©ì–´ ì´í•´ë„ ì ìˆ˜ (0-100)
        2. ìš©ì–´ì‚¬ì „ ì •ì˜ì™€ì˜ ì¼ì¹˜ ì—¬ë¶€ (ìˆëŠ” ê²½ìš°)
        3. ë„ë©”ì¸ ê´€ë ¨ì„± (ì—†ëŠ” ê²½ìš°)
        4. ê°„ë‹¨í•œ ì„¤ëª…
        
        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
        {{
            "term_evaluations": [
                {{
                    "term": "ìš©ì–´1",
                    "score": 85,
                    "matches_dictionary": true,
                    "explanation": "ìš©ì–´ ì„¤ëª…"
                }},
                {{
                    "term": "ìš©ì–´2",
                    "score": 70,
                    "is_domain_related": true,
                    "explanation": "ìš©ì–´ ì„¤ëª…"
                }}
            ],
            "overall_score": 77.5
        }}
        """
        
        try:
            response = azure_llm.completion(
                model=f"azure/{settings.AZURE_OPENAI_DEPLOYMENT_NAME}",
                messages=[{"role": "user", "content": batch_prompt}],
                api_key=settings.AZURE_OPENAI_API_KEY,
                api_base=settings.AZURE_OPENAI_ENDPOINT,
                api_version=settings.AZURE_OPENAI_API_VERSION,
                temperature=0.1
            )
            
            response_text = response.choices[0].message.content
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            if json_start != -1 and json_end != -1:
                json_str = response_text[json_start:json_end]
                batch_result = json.loads(json_str)
                
                term_evaluations = batch_result.get('term_evaluations', [])
                overall_score = batch_result.get('overall_score', 0)
                total_score = overall_score * len(term_evaluations)
                
                print(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: í‰ê·  ì´í•´ë„ {overall_score:.1f}%")
            else:
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
                overall_score = 50
                for term in terms_to_analyze:
                    term_evaluations.append({
                        "term": term,
                        "score": 50,
                        "explanation": "ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨"
                    })
                    total_score += 50
                    
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            overall_score = 0
            for term in terms_to_analyze:
                term_evaluations.append({
                    "term": term,
                    "score": 0,
                    "explanation": f"ì˜¤ë¥˜: {str(e)}"
                })
        # 4. ê²°ê³¼ ì •ë¦¬
        high_terms = [e for e in term_evaluations if e.get("score", 0) >= 70]
        low_terms = [e for e in term_evaluations if e.get("score", 0) < 50]
        
        return {
            "status": "success",
            "csv_file": csv_file_path,
            "total_terms_found": len(all_terms),
            "frequent_terms_count": len(frequent_terms),
            "analyzed_terms": len(terms_to_analyze),
            "overall_score": overall_score,
            "term_evaluations": term_evaluations,
            "high_understanding_terms": high_terms,
            "low_understanding_terms": low_terms,
            "analysis_type": "batch_llm_analysis",
            "message": f"ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: í‰ê·  ì´í•´ë„ {overall_score:.1f}%",
            "summary": {
                "korean_frequent_terms": len(korean_frequent),
                "english_frequent_terms": len(english_frequent),
                "total_frequent_terms": len(frequent_terms),
                "analyzed_terms_count": len(terms_to_analyze),
                "understanding_score": overall_score,
                "low_understanding_terms": len([t for t in term_evaluations if t.get('score', 0) < 70])
            }
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error_message": f"CSV ìš©ì–´ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        }

def get_domain_glossary() -> Dict[str, Any]:
    """ë„ë©”ì¸ ìš©ì–´ ì‚¬ì „ ì¡°íšŒ"""
    print("--- Tool: get_domain_glossary called ---")
    
    try:
        from core.llm.domain_knowledge import DomainTerminology
        domain_terms = DomainTerminology.get_domain_terms()
        technical_terms = DomainTerminology.get_technical_terms()
        business_metrics = DomainTerminology.get_business_metrics()
        
        return {
            "status": "success",
            "domain_terms": domain_terms,
            "technical_terms": technical_terms,
            "business_metrics": business_metrics,
            "total_terms": len(domain_terms) + len(technical_terms) + len(business_metrics),
            "message": "ë„ë©”ì¸ ìš©ì–´ ì‚¬ì „ì„ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error_message": f"ìš©ì–´ ì‚¬ì „ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        }

def validate_csv_terms_simple(csv_file_path: str) -> Dict[str, Any]:
    """ê°„ë‹¨í•œ ìš©ì–´ ê²€ì¦ (LLM í˜¸ì¶œ ì—†ìŒ)"""
    print("--- Tool: validate_csv_terms_simple called ---")
    
    try:
        # 1. CSVì—ì„œ ìš©ì–´ ì¶”ì¶œ
        df = pd.read_csv(csv_file_path)
        all_text = ""
        for col in df.columns:
            if df[col].dtype == 'object':
                all_text += " " + df[col].astype(str).str.cat(sep=" ")
        
        # í•œê¸€ ìš©ì–´ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        korean_terms = re.findall(r'[ê°€-í£]{2,}', all_text)
        english_terms = re.findall(r'[A-Z][a-zA-Z]*', all_text)
        all_terms = list(set(korean_terms + english_terms))
        
        # 2. ë„ë©”ì¸ ìš©ì–´ì‚¬ì „ ë¡œë“œ
        from core.llm.domain_knowledge import DomainTerminology
        domain_terms = DomainTerminology.get_domain_terms()
        technical_terms = DomainTerminology.get_technical_terms()
        business_metrics = DomainTerminology.get_business_metrics()
        all_domain_terms = {**domain_terms, **technical_terms, **business_metrics}
        
        # 3. ê°„ë‹¨í•œ ë§¤ì¹­ ë¶„ì„ (LLM í˜¸ì¶œ ì—†ìŒ)
        matched_terms = []
        unmatched_terms = []
        
        for term in all_terms[:20]:  # ìƒìœ„ 20ê°œë§Œ ë¶„ì„
            if term in all_domain_terms:
                matched_terms.append({
                    "term": term,
                    "definition": all_domain_terms[term],
                    "category": "domain" if term in domain_terms else "technical" if term in technical_terms else "business"
                })
            else:
                unmatched_terms.append(term)
        
        coverage_rate = len(matched_terms) / len(all_terms[:20]) * 100 if all_terms else 0
        
        return {
            "status": "success",
            "csv_file": csv_file_path,
            "total_terms_found": len(all_terms),
            "analyzed_terms": len(all_terms[:20]),
            "matched_terms": matched_terms,
            "unmatched_terms": unmatched_terms[:10],  # ìƒìœ„ 10ê°œë§Œ
            "coverage_rate": coverage_rate,
            "analysis_type": "simple_matching"
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error_message": f"ê°„ë‹¨í•œ ìš©ì–´ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        }
